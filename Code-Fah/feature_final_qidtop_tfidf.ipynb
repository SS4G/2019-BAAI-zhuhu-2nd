{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "import gc\n",
    "import time\n",
    "\n",
    "time_start=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('invite_info.txt',sep='\\s+',names=['qid','uid','time','target'])\n",
    "test=pd.read_csv('invite_info_evaluate_1.txt',sep='\\s+',names=['qid','uid','time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques_info=pd.read_csv('question_info.txt',sep='\\s+',names=['qid','qtime','qtitle','qtitlec','qinfo','qinfoc','qtopic'])\n",
    "member_info=pd.read_csv('member_info.txt',sep='\\s+',names=['uid','sex','key_word','num_level','hot_level','regis_type','regis_platform',\n",
    "                                                          'look_freq','a','b','c','d','e','A','B','C','D','E','salt','l_topic','topic_n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train[['qid','uid','target']]\n",
    "test=test[['qid','uid']]\n",
    "member_info=member_info[['uid','l_topic']]\n",
    "ques_info=ques_info[['qid','qtitlec']]\n",
    "\n",
    "member_info.drop_duplicates(['uid'],inplace=True)\n",
    "ques_info.drop_duplicates(['qid'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.merge(train,member_info,on='uid',how='left')\n",
    "test=pd.merge(test,member_info,on='uid',how='left')\n",
    "\n",
    "train=pd.merge(train,ques_info,on='qid',how='left')\n",
    "test=pd.merge(test,ques_info,on='qid',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10630845"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)+len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10630845, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target=train['target']\n",
    "train.drop(['target'],axis=1,inplace=True)\n",
    "all_data=pd.concat([train,test],axis=0)\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>uid</th>\n",
       "      <th>l_topic</th>\n",
       "      <th>qtitlec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q2166419046</td>\n",
       "      <td>M401693808</td>\n",
       "      <td>T1727,T5310,T3402,T916,T1506,T26329,T7293,T180...</td>\n",
       "      <td>W11058,W272,W2202,W431,W951,W243,W3828,W3037,W263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1550017551</td>\n",
       "      <td>M3392373099</td>\n",
       "      <td>T42595,T3,T8520,T597,T6485,T6212,T25664,T148,T...</td>\n",
       "      <td>W149,W79,W5210,W22869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q604029601</td>\n",
       "      <td>M2317670257</td>\n",
       "      <td>T610,T448,T61,T2801,T9019,T65,T233,T190,T55,T5...</td>\n",
       "      <td>W31489,W9218,W3440,W243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q2350061229</td>\n",
       "      <td>M1618461867</td>\n",
       "      <td>T5,T33331,T2274,T31,T245,T516,T309,T1326,T119,...</td>\n",
       "      <td>W973,W64958,W8583,W2269,W628,W565,W2200,W590,W483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q2443223942</td>\n",
       "      <td>M3544409350</td>\n",
       "      <td>-1</td>\n",
       "      <td>W554,W28208,W396,W51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           qid          uid  \\\n",
       "0  Q2166419046   M401693808   \n",
       "1  Q1550017551  M3392373099   \n",
       "2   Q604029601  M2317670257   \n",
       "3  Q2350061229  M1618461867   \n",
       "4  Q2443223942  M3544409350   \n",
       "\n",
       "                                             l_topic  \\\n",
       "0  T1727,T5310,T3402,T916,T1506,T26329,T7293,T180...   \n",
       "1  T42595,T3,T8520,T597,T6485,T6212,T25664,T148,T...   \n",
       "2  T610,T448,T61,T2801,T9019,T65,T233,T190,T55,T5...   \n",
       "3  T5,T33331,T2274,T31,T245,T516,T309,T1326,T119,...   \n",
       "4                                                 -1   \n",
       "\n",
       "                                             qtitlec  \n",
       "0  W11058,W272,W2202,W431,W951,W243,W3828,W3037,W263  \n",
       "1                              W149,W79,W5210,W22869  \n",
       "2                            W31489,W9218,W3440,W243  \n",
       "3  W973,W64958,W8583,W2269,W628,W565,W2200,W590,W483  \n",
       "4                               W554,W28208,W396,W51  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['l_topic']=all_data['l_topic'].astype(str)\n",
    "all_data['qtitlec']=all_data['qtitlec'].astype(str)\n",
    "all_data['l_topic']=all_data['l_topic'].apply(lambda x:x.split(','))\n",
    "all_data['qtitlec']=all_data['qtitlec'].apply(lambda x:x.split(','))\n",
    "all_data['num_ltopic']=all_data['l_topic'].apply(lambda x:len(x))\n",
    "all_data['num_qtitlec']=all_data['qtitlec'].apply(lambda x:len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['l_topic']=all_data['l_topic'].apply(lambda x:' '.join(x))\n",
    "all_data['qtitlec']=all_data['qtitlec'].apply(lambda x:' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "import gc\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = CountVectorizer(ngram_range=(1,1))\n",
    "tf_ltopic = tfidf.fit_transform(all_data['l_topic'])\n",
    "tfidf = CountVectorizer(ngram_range=(1,1))\n",
    "tf_qtopic = tfidf.fit_transform(all_data['qtitlec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10630845, 79097)\n",
      "(10630845, 130248)\n"
     ]
    }
   ],
   "source": [
    "print(tf_ltopic.shape)\n",
    "print(tf_qtopic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10630845, 209345)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "all_sparse=sparse.csc_matrix(sparse.hstack((tf_ltopic, tf_qtopic)))\n",
    "all_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database is locked',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "train_feature=all_sparse[0:train.shape[0]]\n",
    "test_feature=all_sparse[train.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrstacking():\n",
    "    num_class=2\n",
    "    df_stack=pd.DataFrame()\n",
    "    n_folds=5\n",
    "    gc.collect()\n",
    "    print('LR stacking')\n",
    "    stack_train = np.zeros([train_feature.shape[0], num_class])\n",
    "    stack_test = np.zeros([test_feature.shape[0], num_class])\n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "    for i, (trn_idx, val_idx) in enumerate(folds.split(target)):\n",
    "        print('stack:%d' % ((i + 1) ))\n",
    "        clf = LogisticRegression(random_state=1017, C=8,solver='sag',verbose=1,n_jobs=-1)\n",
    "        clf.fit(train_feature[trn_idx], target[trn_idx])\n",
    "        score_va = clf.predict_proba(train_feature[val_idx])\n",
    "        score_te = clf.predict_proba(test_feature)\n",
    "        stack_train[val_idx, :] = score_va\n",
    "        stack_test[:, :] += score_te\n",
    "    stack_test /= n_folds\n",
    "    stack = np.vstack([stack_train, stack_test])\n",
    "    for i in range(stack.shape[1]):\n",
    "        df_stack['tfc_lr_{}'.format(i)] = stack[:, i]\n",
    "    print('lr done')\n",
    "    return df_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR stacking\n",
      "stack:1\n",
      "max_iter reached after 1784 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed: 29.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stack:2\n",
      "max_iter reached after 1394 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed: 23.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stack:3\n",
      "max_iter reached after 1255 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed: 20.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stack:4\n",
      "max_iter reached after 1311 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed: 21.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stack:5\n",
      "max_iter reached after 1362 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed: 22.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr done\n"
     ]
    }
   ],
   "source": [
    "lrstacking=lrstacking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgdstacking():\n",
    "    gc.collect()\n",
    "    print('sgd stacking')\n",
    "    df_stack=pd.DataFrame()\n",
    "    n_folds=5\n",
    "    num_class=2\n",
    "    stack_train = np.zeros([train_feature.shape[0], num_class])\n",
    "    stack_test = np.zeros([test_feature.shape[0], num_class])\n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "    for i, (tr, va) in enumerate(folds.split(target)):\n",
    "        print('stack:%d/%d' % ((i + 1), n_folds))\n",
    "        sgd = SGDClassifier(random_state=1017,\n",
    "                            verbose=1,\n",
    "                            loss='log',\n",
    "                            penalty='elasticnet',\n",
    "                            shuffle=True,\n",
    "                            n_jobs=20,\n",
    "                            l1_ratio=0.0001,\n",
    "                            alpha=1e-05,\n",
    "                            class_weight=None)\n",
    "        gc.collect()\n",
    "        sgd.fit(train_feature[tr], target[tr])\n",
    "        score_va = sgd.predict_proba(train_feature[va])\n",
    "        score_te = sgd.predict_proba(test_feature)\n",
    "        stack_train[va] = score_va\n",
    "        stack_test += score_te\n",
    "    stack_test /= n_folds\n",
    "    stack = np.vstack([stack_train, stack_test])\n",
    "    for i in range(stack.shape[1]):\n",
    "        df_stack['tfc_sgd_{}'.format(i)] = stack[:, i]\n",
    "    print('sgd done')\n",
    "    return df_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd stacking\n",
      "stack:1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 30.65, NNZs: 197277, Bias: -1.474468, T: 7591329, Avg. loss: 0.623154\n",
      "Total training time: 8.78 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 28.89, NNZs: 197285, Bias: -1.473191, T: 15182658, Avg. loss: 0.451686\n",
      "Total training time: 17.21 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 28.45, NNZs: 197324, Bias: -1.470077, T: 22773987, Avg. loss: 0.447974\n",
      "Total training time: 27.06 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.28, NNZs: 197300, Bias: -1.470500, T: 30365316, Avg. loss: 0.446452\n",
      "Total training time: 36.76 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 28.17, NNZs: 197404, Bias: -1.473007, T: 37956645, Avg. loss: 0.445638\n",
      "Total training time: 46.77 seconds.\n",
      "stack:2/5\n",
      "-- Epoch 1\n",
      "Norm: 30.58, NNZs: 197315, Bias: -1.465340, T: 7591329, Avg. loss: 0.625475\n",
      "Total training time: 9.05 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 28.87, NNZs: 197258, Bias: -1.474226, T: 15182658, Avg. loss: 0.451726\n",
      "Total training time: 18.71 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 28.45, NNZs: 197282, Bias: -1.465607, T: 22773987, Avg. loss: 0.447994\n",
      "Total training time: 27.57 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.26, NNZs: 197305, Bias: -1.469145, T: 30365316, Avg. loss: 0.446466\n",
      "Total training time: 37.18 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 28.17, NNZs: 197350, Bias: -1.471918, T: 37956645, Avg. loss: 0.445636\n",
      "Total training time: 46.85 seconds.\n",
      "stack:3/5\n",
      "-- Epoch 1\n",
      "Norm: 30.64, NNZs: 197279, Bias: -1.459014, T: 7591330, Avg. loss: 0.626042\n",
      "Total training time: 8.70 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 28.90, NNZs: 197183, Bias: -1.466426, T: 15182660, Avg. loss: 0.451758\n",
      "Total training time: 18.77 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 28.48, NNZs: 197310, Bias: -1.472604, T: 22773990, Avg. loss: 0.448036\n",
      "Total training time: 28.63 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.31, NNZs: 197211, Bias: -1.467672, T: 30365320, Avg. loss: 0.446533\n",
      "Total training time: 37.88 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 28.21, NNZs: 197235, Bias: -1.469674, T: 37956650, Avg. loss: 0.445684\n",
      "Total training time: 46.57 seconds.\n",
      "stack:4/5\n",
      "-- Epoch 1\n",
      "Norm: 30.60, NNZs: 197178, Bias: -1.467233, T: 7591330, Avg. loss: 0.624910\n",
      "Total training time: 8.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 28.87, NNZs: 197192, Bias: -1.477316, T: 15182660, Avg. loss: 0.451608\n",
      "Total training time: 16.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 28.47, NNZs: 197186, Bias: -1.471386, T: 22773990, Avg. loss: 0.447869\n",
      "Total training time: 24.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.25, NNZs: 197199, Bias: -1.465871, T: 30365320, Avg. loss: 0.446371\n",
      "Total training time: 33.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 28.15, NNZs: 197239, Bias: -1.473868, T: 37956650, Avg. loss: 0.445528\n",
      "Total training time: 41.66 seconds.\n",
      "stack:5/5\n",
      "-- Epoch 1\n",
      "Norm: 30.56, NNZs: 197413, Bias: -1.459918, T: 7591330, Avg. loss: 0.626280\n",
      "Total training time: 7.98 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 28.82, NNZs: 197379, Bias: -1.459322, T: 15182660, Avg. loss: 0.451866\n",
      "Total training time: 16.25 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 28.41, NNZs: 197273, Bias: -1.467904, T: 22773990, Avg. loss: 0.448161\n",
      "Total training time: 24.34 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.23, NNZs: 197339, Bias: -1.465232, T: 30365320, Avg. loss: 0.446660\n",
      "Total training time: 32.45 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 28.13, NNZs: 197393, Bias: -1.473181, T: 37956650, Avg. loss: 0.445815\n",
      "Total training time: 40.33 seconds.\n",
      "sgd done\n"
     ]
    }
   ],
   "source": [
    "sgdstacking=sgdstacking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridgestacking():\n",
    "    gc.collect()\n",
    "    print('Ridge stacking')\n",
    "    df_stack=pd.DataFrame()\n",
    "    num_class=2\n",
    "    n_folds=5\n",
    "    stack_train = np.zeros([train_feature.shape[0], num_class])\n",
    "    stack_test = np.zeros([test_feature.shape[0], num_class])\n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "    for i, (tr, va) in enumerate(folds.split(target)):\n",
    "        print('stack:%d/%d' % ((i + 1), n_folds))\n",
    "        ridge = RidgeClassifier(random_state=1017,solver='sag',)\n",
    "        ridge.fit(train_feature[tr], target[tr])\n",
    "        score_va = ridge._predict_proba_lr(train_feature[va])\n",
    "        score_te = ridge._predict_proba_lr(test_feature)\n",
    "        stack_train[va] += score_va\n",
    "        stack_test += score_te\n",
    "    stack_test /= n_folds\n",
    "    stack = np.vstack([stack_train, stack_test])\n",
    "    for i in range(stack.shape[1]):\n",
    "        df_stack['tfc_ridge_{}'.format(i)] = stack[:, i]\n",
    "    print('ridge done')\n",
    "    return df_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge stacking\n",
      "stack:1/5\n",
      "stack:2/5\n",
      "stack:3/5\n",
      "stack:4/5\n",
      "stack:5/5\n",
      "ridge done\n"
     ]
    }
   ],
   "source": [
    "ridgestacking=ridgestacking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfc_lr_0</th>\n",
       "      <th>tfc_lr_1</th>\n",
       "      <th>tfc_sgd_0</th>\n",
       "      <th>tfc_sgd_1</th>\n",
       "      <th>tfc_ridge_0</th>\n",
       "      <th>tfc_ridge_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.935751</td>\n",
       "      <td>0.064249</td>\n",
       "      <td>0.934477</td>\n",
       "      <td>0.065523</td>\n",
       "      <td>0.703916</td>\n",
       "      <td>0.296084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.844869</td>\n",
       "      <td>0.155131</td>\n",
       "      <td>0.815090</td>\n",
       "      <td>0.184910</td>\n",
       "      <td>0.665241</td>\n",
       "      <td>0.334759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.869858</td>\n",
       "      <td>0.130142</td>\n",
       "      <td>0.887802</td>\n",
       "      <td>0.112198</td>\n",
       "      <td>0.673109</td>\n",
       "      <td>0.326891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.854217</td>\n",
       "      <td>0.145783</td>\n",
       "      <td>0.842922</td>\n",
       "      <td>0.157078</td>\n",
       "      <td>0.665344</td>\n",
       "      <td>0.334656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.697233</td>\n",
       "      <td>0.302767</td>\n",
       "      <td>0.754147</td>\n",
       "      <td>0.245853</td>\n",
       "      <td>0.597356</td>\n",
       "      <td>0.402644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tfc_lr_0  tfc_lr_1  tfc_sgd_0  tfc_sgd_1  tfc_ridge_0  tfc_ridge_1\n",
       "0  0.935751  0.064249   0.934477   0.065523     0.703916     0.296084\n",
       "1  0.844869  0.155131   0.815090   0.184910     0.665241     0.334759\n",
       "2  0.869858  0.130142   0.887802   0.112198     0.673109     0.326891\n",
       "3  0.854217  0.145783   0.842922   0.157078     0.665344     0.334656\n",
       "4  0.697233  0.302767   0.754147   0.245853     0.597356     0.402644"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=pd.concat([lrstacking,sgdstacking,ridgestacking],axis=1)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10630845"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.columns=['tfc_lr_q', 'tfc_lr_1', 'tfc_sgd_q', 'tfc_sgd_1', 'tfc_ridge_q','tfc_ridge_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[['tfc_lr_q', 'tfc_sgd_q', 'tfc_ridge_q']].to_csv('feature_qidtop_tfidf.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totally cost 32560.318981409073\n"
     ]
    }
   ],
   "source": [
    "time_end=time.time()\n",
    "print('totally cost',time_end-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
