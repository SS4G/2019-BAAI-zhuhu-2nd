{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=pd.read_hdf('stacking_lgb8568.h5', key='data').reset_index(drop=True)\n",
    "model1.columns=['lgb_nonn']\n",
    "model2=pd.read_hdf('stacking849.h5', key='data').reset_index(drop=True)\n",
    "model2.columns=['nn_fea']\n",
    "model3=pd.read_hdf('stacking86148.h5', key='data').reset_index(drop=True)\n",
    "model4=pd.read_hdf('stacking_nn_no_fea_cv7324.h5', key='data').reset_index(drop=True)\n",
    "model5=pd.read_hdf('stacking_nn_char_cv7320.h5', key='data').reset_index(drop=True)\n",
    "model6=pd.read_hdf('stacking_nn_LSTUR_cv68.h5', key='data').reset_index(drop=True)\n",
    "model7=pd.read_hdf('stackingesim.h5', key='data').reset_index(drop=True)\n",
    "model8=pd.read_hdf('stacking_lgb2.h5', key='data').reset_index(drop=True)\n",
    "\n",
    "feature_topic_w2vdis=pd.read_hdf('stacking_nn_LSTUR_cv867.h5', key='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nn_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.071229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.134450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.219796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.003629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.149206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.646612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.624932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.180611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.471070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.180614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.196282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.691365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.796223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.161249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.139101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.003577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.109225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.074850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.242765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.012474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.003939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.085780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.865263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.893975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.355041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630815</th>\n",
       "      <td>0.192710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630816</th>\n",
       "      <td>0.099828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630817</th>\n",
       "      <td>0.527100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630818</th>\n",
       "      <td>0.042496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630819</th>\n",
       "      <td>0.021930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630820</th>\n",
       "      <td>0.057632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630821</th>\n",
       "      <td>0.020484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630822</th>\n",
       "      <td>0.130056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630823</th>\n",
       "      <td>0.430635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630824</th>\n",
       "      <td>0.007551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630825</th>\n",
       "      <td>0.504676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630826</th>\n",
       "      <td>0.240145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630827</th>\n",
       "      <td>0.142930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630828</th>\n",
       "      <td>0.001278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630829</th>\n",
       "      <td>0.178724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630830</th>\n",
       "      <td>0.002897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630831</th>\n",
       "      <td>0.002079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630832</th>\n",
       "      <td>0.443629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630833</th>\n",
       "      <td>0.373350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630834</th>\n",
       "      <td>0.416801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630835</th>\n",
       "      <td>0.173562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630836</th>\n",
       "      <td>0.175236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630837</th>\n",
       "      <td>0.246148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630838</th>\n",
       "      <td>0.016560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630839</th>\n",
       "      <td>0.015099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630840</th>\n",
       "      <td>0.039631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630841</th>\n",
       "      <td>0.603351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630842</th>\n",
       "      <td>0.426406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630843</th>\n",
       "      <td>0.008105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630844</th>\n",
       "      <td>0.093559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10630845 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          nn_feature\n",
       "0           0.003649\n",
       "1           0.014941\n",
       "2           0.018625\n",
       "3           0.001115\n",
       "4           0.011770\n",
       "5           0.071229\n",
       "6           0.134450\n",
       "7           0.219796\n",
       "8           0.003629\n",
       "9           0.149206\n",
       "10          0.646612\n",
       "11          0.624932\n",
       "12          0.180611\n",
       "13          0.471070\n",
       "14          0.180614\n",
       "15          0.196282\n",
       "16          0.691365\n",
       "17          0.796223\n",
       "18          0.161249\n",
       "19          0.139101\n",
       "20          0.003577\n",
       "21          0.109225\n",
       "22          0.074850\n",
       "23          0.242765\n",
       "24          0.012474\n",
       "25          0.003939\n",
       "26          0.085780\n",
       "27          0.865263\n",
       "28          0.893975\n",
       "29          0.355041\n",
       "...              ...\n",
       "10630815    0.192710\n",
       "10630816    0.099828\n",
       "10630817    0.527100\n",
       "10630818    0.042496\n",
       "10630819    0.021930\n",
       "10630820    0.057632\n",
       "10630821    0.020484\n",
       "10630822    0.130056\n",
       "10630823    0.430635\n",
       "10630824    0.007551\n",
       "10630825    0.504676\n",
       "10630826    0.240145\n",
       "10630827    0.142930\n",
       "10630828    0.001278\n",
       "10630829    0.178724\n",
       "10630830    0.002897\n",
       "10630831    0.002079\n",
       "10630832    0.443629\n",
       "10630833    0.373350\n",
       "10630834    0.416801\n",
       "10630835    0.173562\n",
       "10630836    0.175236\n",
       "10630837    0.246148\n",
       "10630838    0.016560\n",
       "10630839    0.015099\n",
       "10630840    0.039631\n",
       "10630841    0.603351\n",
       "10630842    0.426406\n",
       "10630843    0.008105\n",
       "10630844    0.093559\n",
       "\n",
       "[10630845 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.379168e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.280587e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.813744e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.991170e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.912545e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.774020e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.765377e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.421889e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.231442e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.325881e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.625245e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.048838e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.651338e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.275088e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.594085e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.342334e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7.393764e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7.887084e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.072562e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8.200074e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8.038955e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.228057e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.142749e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.624933e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.035090e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6.202129e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.015612e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7.510634e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9.077331e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6.729537e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630815</th>\n",
       "      <td>1.905920e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630816</th>\n",
       "      <td>5.526068e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630817</th>\n",
       "      <td>5.883237e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630818</th>\n",
       "      <td>5.166788e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630819</th>\n",
       "      <td>2.006847e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630820</th>\n",
       "      <td>1.203145e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630821</th>\n",
       "      <td>2.156030e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630822</th>\n",
       "      <td>1.213765e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630823</th>\n",
       "      <td>3.478537e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630824</th>\n",
       "      <td>1.712095e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630825</th>\n",
       "      <td>4.693560e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630826</th>\n",
       "      <td>1.221298e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630827</th>\n",
       "      <td>1.689204e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630828</th>\n",
       "      <td>1.756805e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630829</th>\n",
       "      <td>7.370432e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630830</th>\n",
       "      <td>9.772496e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630831</th>\n",
       "      <td>8.503682e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630832</th>\n",
       "      <td>2.554330e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630833</th>\n",
       "      <td>3.634419e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630834</th>\n",
       "      <td>2.250328e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630835</th>\n",
       "      <td>2.013823e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630836</th>\n",
       "      <td>1.164152e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630837</th>\n",
       "      <td>2.915957e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630838</th>\n",
       "      <td>1.811290e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630839</th>\n",
       "      <td>2.613133e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630840</th>\n",
       "      <td>4.761307e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630841</th>\n",
       "      <td>4.963913e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630842</th>\n",
       "      <td>2.692290e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630843</th>\n",
       "      <td>8.739427e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630844</th>\n",
       "      <td>4.856752e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10630845 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "0         5.379168e-03\n",
       "1         3.280587e-02\n",
       "2         1.813744e-02\n",
       "3         1.991170e-03\n",
       "4         2.912545e-02\n",
       "5         1.774020e-01\n",
       "6         8.765377e-02\n",
       "7         1.421889e-01\n",
       "8         1.231442e-03\n",
       "9         1.325881e-01\n",
       "10        7.625245e-01\n",
       "11        6.048838e-01\n",
       "12        1.651338e-01\n",
       "13        4.275088e-01\n",
       "14        1.594085e-01\n",
       "15        7.342334e-02\n",
       "16        7.393764e-01\n",
       "17        7.887084e-01\n",
       "18        2.072562e-01\n",
       "19        8.200074e-02\n",
       "20        8.038955e-04\n",
       "21        1.228057e-01\n",
       "22        1.142749e-01\n",
       "23        2.624933e-01\n",
       "24        2.035090e-02\n",
       "25        6.202129e-03\n",
       "26        1.015612e-01\n",
       "27        7.510634e-01\n",
       "28        9.077331e-01\n",
       "29        6.729537e-01\n",
       "...                ...\n",
       "10630815  1.905920e-01\n",
       "10630816  5.526068e-02\n",
       "10630817  5.883237e-01\n",
       "10630818  5.166788e-02\n",
       "10630819  2.006847e-02\n",
       "10630820  1.203145e-01\n",
       "10630821  2.156030e-02\n",
       "10630822  1.213765e-01\n",
       "10630823  3.478537e-01\n",
       "10630824  1.712095e-02\n",
       "10630825  4.693560e-01\n",
       "10630826  1.221298e-01\n",
       "10630827  1.689204e-01\n",
       "10630828  1.756805e-03\n",
       "10630829  7.370432e-02\n",
       "10630830  9.772496e-03\n",
       "10630831  8.503682e-09\n",
       "10630832  2.554330e-01\n",
       "10630833  3.634419e-01\n",
       "10630834  2.250328e-01\n",
       "10630835  2.013823e-01\n",
       "10630836  1.164152e-01\n",
       "10630837  2.915957e-01\n",
       "10630838  1.811290e-02\n",
       "10630839  2.613133e-02\n",
       "10630840  4.761307e-02\n",
       "10630841  4.963913e-01\n",
       "10630842  2.692290e-01\n",
       "10630843  8.739427e-03\n",
       "10630844  4.856752e-02\n",
       "\n",
       "[10630845 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('invite_info.txt',sep='\\s+',names=['qid','uid','time','target'])\n",
    "test=pd.read_csv('invite_info_evaluate_1.txt',sep='\\s+',names=['qid','uid','time'])\n",
    "target=train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.concat([train,\n",
    "                 model1.iloc[0:train.shape[0],:],\n",
    "                 model2.iloc[0:train.shape[0],:],\n",
    "                 model3.iloc[0:train.shape[0],:],\n",
    "                 model4.iloc[0:train.shape[0],:],\n",
    "                 model5.iloc[0:train.shape[0],:],\n",
    "                 model6.iloc[0:train.shape[0],:], \n",
    "                 model7.iloc[0:train.shape[0],:],\n",
    "                 feature_topic_w2vdis.iloc[0:train.shape[0],:],\n",
    "                 model8.iloc[0:train.shape[0],:],\n",
    "                ],axis=1)\n",
    "test=pd.concat([test,\n",
    "                model1.iloc[train.shape[0]:,:].reset_index(drop=True),\n",
    "                model2.iloc[train.shape[0]:,:].reset_index(drop=True),\n",
    "                model3.iloc[train.shape[0]:,:].reset_index(drop=True),\n",
    "                model4.iloc[train.shape[0]:,:].reset_index(drop=True),\n",
    "                model5.iloc[train.shape[0]:,:].reset_index(drop=True),\n",
    "                model6.iloc[train.shape[0]:,:].reset_index(drop=True),\n",
    "                model7.iloc[train.shape[0]:,:].reset_index(drop=True),\n",
    "                feature_topic_w2vdis.iloc[train.shape[0]:,:].reset_index(drop=True),\n",
    "                model8.iloc[train.shape[0]:,:].reset_index(drop=True),\n",
    "               ],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(['uid','qid','time'], axis=1)\n",
    "train = train.drop(['target', 'uid','qid','time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgb_nonn</th>\n",
       "      <th>nn_fea</th>\n",
       "      <th>nn_feature</th>\n",
       "      <th>nn_no_fea</th>\n",
       "      <th>nn_char</th>\n",
       "      <th>nn_LSTUR</th>\n",
       "      <th>esim_feature</th>\n",
       "      <th>nn_LSTURPro</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.003649</td>\n",
       "      <td>0.157505</td>\n",
       "      <td>0.074546</td>\n",
       "      <td>0.120644</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.005379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.028877</td>\n",
       "      <td>0.019841</td>\n",
       "      <td>0.014941</td>\n",
       "      <td>0.243975</td>\n",
       "      <td>0.122339</td>\n",
       "      <td>0.175346</td>\n",
       "      <td>0.024112</td>\n",
       "      <td>0.050738</td>\n",
       "      <td>0.032806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.017263</td>\n",
       "      <td>0.013798</td>\n",
       "      <td>0.018625</td>\n",
       "      <td>0.089800</td>\n",
       "      <td>0.036616</td>\n",
       "      <td>0.054157</td>\n",
       "      <td>0.063057</td>\n",
       "      <td>0.053058</td>\n",
       "      <td>0.018137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003853</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>0.029673</td>\n",
       "      <td>0.113823</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.006831</td>\n",
       "      <td>0.001991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022466</td>\n",
       "      <td>0.009935</td>\n",
       "      <td>0.011770</td>\n",
       "      <td>0.192788</td>\n",
       "      <td>0.175256</td>\n",
       "      <td>0.232572</td>\n",
       "      <td>0.019896</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.029125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lgb_nonn    nn_fea  nn_feature  nn_no_fea   nn_char  nn_LSTUR  \\\n",
       "0  0.001771  0.001096    0.003649   0.157505  0.074546  0.120644   \n",
       "1  0.028877  0.019841    0.014941   0.243975  0.122339  0.175346   \n",
       "2  0.017263  0.013798    0.018625   0.089800  0.036616  0.054157   \n",
       "3  0.003853  0.001041    0.001115   0.000979  0.029673  0.113823   \n",
       "4  0.022466  0.009935    0.011770   0.192788  0.175256  0.232572   \n",
       "\n",
       "   esim_feature  nn_LSTURPro         0  \n",
       "0      0.000879     0.000986  0.005379  \n",
       "1      0.024112     0.050738  0.032806  \n",
       "2      0.063057     0.053058  0.018137  \n",
       "3      0.000303     0.006831  0.001991  \n",
       "4      0.019896     0.004325  0.029125  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves': 30,\n",
    "         'objective':'binary',\n",
    "         'learning_rate': 0.1,         \n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.8,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.8 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'auc',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"random_state\": 133,\n",
    "         \"verbosity\": -1,\n",
    "         \"num_threads\" : -1,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "feature_importance_df = pd.DataFrame()\n",
    "predictions=np.zeros([len(test),1])\n",
    "stack_train = np.zeros((len(train),1))\n",
    "stack_test = np.zeros((len(test),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold nÂ°0\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[10]\ttraining's auc: 0.8934\tvalid_1's auc: 0.892921\n",
      "[20]\ttraining's auc: 0.893768\tvalid_1's auc: 0.893278\n",
      "[30]\ttraining's auc: 0.893944\tvalid_1's auc: 0.893469\n",
      "[40]\ttraining's auc: 0.894062\tvalid_1's auc: 0.893581\n",
      "[50]\ttraining's auc: 0.89415\tvalid_1's auc: 0.893662\n",
      "[60]\ttraining's auc: 0.894221\tvalid_1's auc: 0.893722\n",
      "[70]\ttraining's auc: 0.894278\tvalid_1's auc: 0.893759\n",
      "[80]\ttraining's auc: 0.894316\tvalid_1's auc: 0.893781\n",
      "[90]\ttraining's auc: 0.894351\tvalid_1's auc: 0.893781\n",
      "[100]\ttraining's auc: 0.894348\tvalid_1's auc: 0.89374\n",
      "[110]\ttraining's auc: 0.894359\tvalid_1's auc: 0.893725\n",
      "[120]\ttraining's auc: 0.894367\tvalid_1's auc: 0.893722\n",
      "[130]\ttraining's auc: 0.894357\tvalid_1's auc: 0.8937\n",
      "[140]\ttraining's auc: 0.89434\tvalid_1's auc: 0.893665\n",
      "[150]\ttraining's auc: 0.892992\tvalid_1's auc: 0.892187\n",
      "[160]\ttraining's auc: 0.894201\tvalid_1's auc: 0.893517\n",
      "[170]\ttraining's auc: 0.894304\tvalid_1's auc: 0.893632\n",
      "[180]\ttraining's auc: 0.894346\tvalid_1's auc: 0.893681\n",
      "[190]\ttraining's auc: 0.894333\tvalid_1's auc: 0.893652\n",
      "[200]\ttraining's auc: 0.894338\tvalid_1's auc: 0.89365\n",
      "[210]\ttraining's auc: 0.894334\tvalid_1's auc: 0.893636\n",
      "[220]\ttraining's auc: 0.894338\tvalid_1's auc: 0.893656\n",
      "[230]\ttraining's auc: 0.894332\tvalid_1's auc: 0.893656\n",
      "[240]\ttraining's auc: 0.894319\tvalid_1's auc: 0.893656\n",
      "[250]\ttraining's auc: 0.894283\tvalid_1's auc: 0.893611\n",
      "[260]\ttraining's auc: 0.894266\tvalid_1's auc: 0.893593\n",
      "[270]\ttraining's auc: 0.894289\tvalid_1's auc: 0.89363\n",
      "[280]\ttraining's auc: 0.894306\tvalid_1's auc: 0.893655\n",
      "Early stopping, best iteration is:\n",
      "[88]\ttraining's auc: 0.894349\tvalid_1's auc: 0.893788\n",
      "0.2059228100987091\n",
      "fold nÂ°1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[10]\ttraining's auc: 0.89328\tvalid_1's auc: 0.893301\n",
      "[20]\ttraining's auc: 0.893649\tvalid_1's auc: 0.893716\n",
      "[30]\ttraining's auc: 0.893841\tvalid_1's auc: 0.893858\n",
      "[40]\ttraining's auc: 0.893984\tvalid_1's auc: 0.893965\n",
      "[50]\ttraining's auc: 0.894081\tvalid_1's auc: 0.894023\n",
      "[60]\ttraining's auc: 0.89415\tvalid_1's auc: 0.894057\n",
      "[70]\ttraining's auc: 0.894202\tvalid_1's auc: 0.894076\n",
      "[80]\ttraining's auc: 0.89425\tvalid_1's auc: 0.894085\n",
      "[90]\ttraining's auc: 0.894285\tvalid_1's auc: 0.894093\n",
      "[100]\ttraining's auc: 0.894321\tvalid_1's auc: 0.894101\n",
      "[110]\ttraining's auc: 0.894357\tvalid_1's auc: 0.894106\n",
      "[120]\ttraining's auc: 0.894384\tvalid_1's auc: 0.894097\n",
      "[130]\ttraining's auc: 0.894384\tvalid_1's auc: 0.894086\n",
      "[140]\ttraining's auc: 0.89439\tvalid_1's auc: 0.894081\n",
      "[150]\ttraining's auc: 0.894393\tvalid_1's auc: 0.894061\n",
      "[160]\ttraining's auc: 0.894371\tvalid_1's auc: 0.894033\n",
      "[170]\ttraining's auc: 0.89425\tvalid_1's auc: 0.893927\n",
      "[180]\ttraining's auc: 0.89438\tvalid_1's auc: 0.894044\n",
      "[190]\ttraining's auc: 0.894353\tvalid_1's auc: 0.894014\n",
      "[200]\ttraining's auc: 0.894319\tvalid_1's auc: 0.893969\n",
      "[210]\ttraining's auc: 0.89435\tvalid_1's auc: 0.893983\n",
      "[220]\ttraining's auc: 0.894293\tvalid_1's auc: 0.893911\n",
      "[230]\ttraining's auc: 0.894377\tvalid_1's auc: 0.894011\n",
      "[240]\ttraining's auc: 0.894348\tvalid_1's auc: 0.894009\n",
      "[250]\ttraining's auc: 0.894335\tvalid_1's auc: 0.893983\n",
      "[260]\ttraining's auc: 0.894355\tvalid_1's auc: 0.894005\n",
      "[270]\ttraining's auc: 0.894276\tvalid_1's auc: 0.89392\n",
      "[280]\ttraining's auc: 0.894351\tvalid_1's auc: 0.893993\n",
      "[290]\ttraining's auc: 0.894354\tvalid_1's auc: 0.894002\n",
      "[300]\ttraining's auc: 0.894288\tvalid_1's auc: 0.89394\n",
      "[310]\ttraining's auc: 0.894339\tvalid_1's auc: 0.893953\n",
      "Early stopping, best iteration is:\n",
      "[114]\ttraining's auc: 0.894373\tvalid_1's auc: 0.894107\n",
      "0.41201861546307916\n",
      "fold nÂ°2\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[10]\ttraining's auc: 0.89337\tvalid_1's auc: 0.893212\n",
      "[20]\ttraining's auc: 0.893697\tvalid_1's auc: 0.893513\n",
      "[30]\ttraining's auc: 0.893896\tvalid_1's auc: 0.89371\n",
      "[40]\ttraining's auc: 0.894017\tvalid_1's auc: 0.893821\n",
      "[50]\ttraining's auc: 0.894112\tvalid_1's auc: 0.893904\n",
      "[60]\ttraining's auc: 0.894178\tvalid_1's auc: 0.89395\n",
      "[70]\ttraining's auc: 0.894229\tvalid_1's auc: 0.893973\n",
      "[80]\ttraining's auc: 0.894274\tvalid_1's auc: 0.89399\n",
      "[90]\ttraining's auc: 0.894318\tvalid_1's auc: 0.894004\n",
      "[100]\ttraining's auc: 0.89435\tvalid_1's auc: 0.894004\n",
      "[110]\ttraining's auc: 0.894362\tvalid_1's auc: 0.893973\n",
      "[120]\ttraining's auc: 0.894371\tvalid_1's auc: 0.893969\n",
      "[130]\ttraining's auc: 0.89438\tvalid_1's auc: 0.893948\n",
      "[140]\ttraining's auc: 0.894353\tvalid_1's auc: 0.893909\n",
      "[150]\ttraining's auc: 0.894369\tvalid_1's auc: 0.893899\n",
      "[160]\ttraining's auc: 0.89439\tvalid_1's auc: 0.893926\n",
      "[170]\ttraining's auc: 0.894373\tvalid_1's auc: 0.893917\n",
      "[180]\ttraining's auc: 0.894348\tvalid_1's auc: 0.893876\n",
      "[190]\ttraining's auc: 0.894328\tvalid_1's auc: 0.893852\n",
      "[200]\ttraining's auc: 0.894314\tvalid_1's auc: 0.893744\n",
      "[210]\ttraining's auc: 0.894294\tvalid_1's auc: 0.893734\n",
      "[220]\ttraining's auc: 0.894331\tvalid_1's auc: 0.893739\n",
      "[230]\ttraining's auc: 0.894351\tvalid_1's auc: 0.893788\n",
      "[240]\ttraining's auc: 0.894253\tvalid_1's auc: 0.893716\n",
      "[250]\ttraining's auc: 0.894343\tvalid_1's auc: 0.89381\n",
      "[260]\ttraining's auc: 0.894315\tvalid_1's auc: 0.893811\n",
      "[270]\ttraining's auc: 0.89429\tvalid_1's auc: 0.893769\n",
      "[280]\ttraining's auc: 0.894309\tvalid_1's auc: 0.89379\n",
      "[290]\ttraining's auc: 0.894266\tvalid_1's auc: 0.893757\n",
      "[300]\ttraining's auc: 0.894233\tvalid_1's auc: 0.893765\n",
      "Early stopping, best iteration is:\n",
      "[104]\ttraining's auc: 0.894368\tvalid_1's auc: 0.894008\n",
      "0.6182889596404672\n",
      "fold nÂ°3\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[10]\ttraining's auc: 0.893216\tvalid_1's auc: 0.893693\n",
      "[20]\ttraining's auc: 0.893583\tvalid_1's auc: 0.894008\n",
      "[30]\ttraining's auc: 0.893772\tvalid_1's auc: 0.894184\n",
      "[40]\ttraining's auc: 0.893896\tvalid_1's auc: 0.894296\n",
      "[50]\ttraining's auc: 0.893982\tvalid_1's auc: 0.894374\n",
      "[60]\ttraining's auc: 0.894048\tvalid_1's auc: 0.894426\n",
      "[70]\ttraining's auc: 0.894102\tvalid_1's auc: 0.894458\n",
      "[80]\ttraining's auc: 0.894143\tvalid_1's auc: 0.894482\n",
      "[90]\ttraining's auc: 0.89416\tvalid_1's auc: 0.894443\n",
      "[100]\ttraining's auc: 0.894183\tvalid_1's auc: 0.894453\n",
      "[110]\ttraining's auc: 0.894209\tvalid_1's auc: 0.894454\n",
      "[120]\ttraining's auc: 0.894226\tvalid_1's auc: 0.894454\n",
      "[130]\ttraining's auc: 0.894219\tvalid_1's auc: 0.894422\n",
      "[140]\ttraining's auc: 0.893923\tvalid_1's auc: 0.894116\n",
      "[150]\ttraining's auc: 0.894096\tvalid_1's auc: 0.894275\n",
      "[160]\ttraining's auc: 0.894021\tvalid_1's auc: 0.894253\n",
      "[170]\ttraining's auc: 0.894149\tvalid_1's auc: 0.894361\n",
      "[180]\ttraining's auc: 0.894192\tvalid_1's auc: 0.894389\n",
      "[190]\ttraining's auc: 0.894208\tvalid_1's auc: 0.89442\n",
      "[200]\ttraining's auc: 0.894196\tvalid_1's auc: 0.894393\n",
      "[210]\ttraining's auc: 0.894201\tvalid_1's auc: 0.894411\n",
      "[220]\ttraining's auc: 0.894201\tvalid_1's auc: 0.894398\n",
      "[230]\ttraining's auc: 0.894176\tvalid_1's auc: 0.894345\n",
      "[240]\ttraining's auc: 0.894194\tvalid_1's auc: 0.894362\n",
      "[250]\ttraining's auc: 0.894199\tvalid_1's auc: 0.894368\n",
      "[260]\ttraining's auc: 0.894191\tvalid_1's auc: 0.894362\n",
      "[270]\ttraining's auc: 0.894182\tvalid_1's auc: 0.894341\n",
      "[280]\ttraining's auc: 0.894148\tvalid_1's auc: 0.894316\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's auc: 0.894143\tvalid_1's auc: 0.894482\n",
      "0.8242980206555335\n",
      "fold nÂ°4\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[10]\ttraining's auc: 0.893349\tvalid_1's auc: 0.892987\n",
      "[20]\ttraining's auc: 0.893726\tvalid_1's auc: 0.89336\n",
      "[30]\ttraining's auc: 0.893919\tvalid_1's auc: 0.89353\n",
      "[40]\ttraining's auc: 0.894051\tvalid_1's auc: 0.893639\n",
      "[50]\ttraining's auc: 0.894153\tvalid_1's auc: 0.893707\n",
      "[60]\ttraining's auc: 0.894222\tvalid_1's auc: 0.893746\n",
      "[70]\ttraining's auc: 0.894276\tvalid_1's auc: 0.893759\n",
      "[80]\ttraining's auc: 0.894327\tvalid_1's auc: 0.893763\n",
      "[90]\ttraining's auc: 0.894366\tvalid_1's auc: 0.893772\n",
      "[100]\ttraining's auc: 0.894397\tvalid_1's auc: 0.893765\n",
      "[110]\ttraining's auc: 0.894397\tvalid_1's auc: 0.89373\n",
      "[120]\ttraining's auc: 0.894389\tvalid_1's auc: 0.893713\n",
      "[130]\ttraining's auc: 0.894379\tvalid_1's auc: 0.893684\n",
      "[140]\ttraining's auc: 0.894409\tvalid_1's auc: 0.893686\n",
      "[150]\ttraining's auc: 0.89441\tvalid_1's auc: 0.893669\n",
      "[160]\ttraining's auc: 0.89439\tvalid_1's auc: 0.893646\n",
      "[170]\ttraining's auc: 0.894398\tvalid_1's auc: 0.893646\n",
      "[180]\ttraining's auc: 0.894412\tvalid_1's auc: 0.893663\n",
      "[190]\ttraining's auc: 0.894275\tvalid_1's auc: 0.893505\n",
      "[200]\ttraining's auc: 0.8944\tvalid_1's auc: 0.893657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[210]\ttraining's auc: 0.894384\tvalid_1's auc: 0.893649\n",
      "[220]\ttraining's auc: 0.894015\tvalid_1's auc: 0.893271\n",
      "[230]\ttraining's auc: 0.89432\tvalid_1's auc: 0.893599\n",
      "[240]\ttraining's auc: 0.894352\tvalid_1's auc: 0.893634\n",
      "[250]\ttraining's auc: 0.8943\tvalid_1's auc: 0.89359\n",
      "[260]\ttraining's auc: 0.894375\tvalid_1's auc: 0.893653\n",
      "[270]\ttraining's auc: 0.894318\tvalid_1's auc: 0.893606\n",
      "[280]\ttraining's auc: 0.894335\tvalid_1's auc: 0.893635\n",
      "[290]\ttraining's auc: 0.894318\tvalid_1's auc: 0.893623\n",
      "Early stopping, best iteration is:\n",
      "[91]\ttraining's auc: 0.894371\tvalid_1's auc: 0.893773\n",
      "1.0304924619901406\n"
     ]
    }
   ],
   "source": [
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "#for trn_idx, val_idx in folds.split(train.values, groups=uid):\n",
    "\n",
    "    print(\"fold nÂ°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train.iloc[trn_idx],\n",
    "                           label=target.iloc[trn_idx],\n",
    "                           )\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx],\n",
    "                           label=target.iloc[val_idx],\n",
    "                           )\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param,\n",
    "                    trn_data,\n",
    "                    num_round,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    verbose_eval=10,\n",
    "                    early_stopping_rounds=200)\n",
    "    #stack_train[val_idx, :] =clf.predict(train.iloc[val_idx], num_iteration=clf.best_iteration).reshape(-1,1)\n",
    "    stack_test += clf.predict(test, num_iteration=clf.best_iteration).reshape(-1,1)\n",
    "    print(stack_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0304924619901406"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id=pd.read_csv('invite_info_evaluate_1.txt',sep='\\s+',names=['qid','uid','time'])\n",
    "test_id['target']=stack_test/5\n",
    "test_id.to_csv('result_zf1216.txt',index=False, sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6099031622110261"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2064356970637019"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(test, num_iteration=clf.best_iteration).reshape(-1,1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
