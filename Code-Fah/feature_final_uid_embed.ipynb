{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer,HashingVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD,SparsePCA\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,f1_score,recall_score\n",
    "import gc\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('invite_info.txt',sep='\\s+',names=['qid','uid','time','target'])\n",
    "test=pd.read_csv('invite_info_evaluate_1.txt',sep='\\s+',names=['qid','uid','time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "from scipy import linalg\n",
    "from scipy.special import iv\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "class ProNE():\n",
    "    def __init__(self, G, emb_size=128, step=10, theta=0.5, mu=0.2, n_iter=5, random_state=2019):\n",
    "        self.G = G\n",
    "        self.emb_size = emb_size\n",
    "        self.G = self.G.to_undirected()\n",
    "        self.node_number = self.G.number_of_nodes()\n",
    "        self.random_state = random_state\n",
    "        self.step = step\n",
    "        self.theta = theta\n",
    "        self.mu = mu\n",
    "        self.n_iter = n_iter\n",
    "        \n",
    "        mat = scipy.sparse.lil_matrix((self.node_number, self.node_number))\n",
    "\n",
    "        for e in tqdm(self.G.edges()):\n",
    "            if e[0] != e[1]:\n",
    "                mat[int(e[0]), int(e[1])] = 1\n",
    "                mat[int(e[1]), int(e[0])] = 1\n",
    "        self.mat = scipy.sparse.csr_matrix(mat)\n",
    "        print(mat.shape)\n",
    "\n",
    "    def get_embedding_rand(self, matrix):\n",
    "        # Sparse randomized tSVD for fast embedding\n",
    "        t1 = time.time()\n",
    "        l = matrix.shape[0]\n",
    "        smat = scipy.sparse.csc_matrix(matrix)  # convert to sparse CSC format\n",
    "        print('svd sparse', smat.data.shape[0] * 1.0 / l ** 2)\n",
    "        U, Sigma, VT = randomized_svd(smat, n_components=self.emb_size, n_iter=self.n_iter, random_state=self.random_state)\n",
    "        U = U * np.sqrt(Sigma)\n",
    "        U = preprocessing.normalize(U, \"l2\")\n",
    "        print('sparsesvd time', time.time() - t1)\n",
    "        return U\n",
    "\n",
    "    def get_embedding_dense(self, matrix, emb_size):\n",
    "        # get dense embedding via SVD\n",
    "        t1 = time.time()\n",
    "        U, s, Vh = linalg.svd(matrix, full_matrices=False, check_finite=False, overwrite_a=True)\n",
    "        U = np.array(U)\n",
    "        U = U[:, :emb_size]\n",
    "        s = s[:emb_size]\n",
    "        s = np.sqrt(s)\n",
    "        U = U * s\n",
    "        U = preprocessing.normalize(U, \"l2\")\n",
    "        print('densesvd time', time.time() - t1)\n",
    "        return U\n",
    "\n",
    "    def fit(self, tran, mask):\n",
    "        # Network Embedding as Sparse Matrix Factorization\n",
    "        t1 = time.time()\n",
    "        l1 = 0.75\n",
    "        C1 = preprocessing.normalize(tran, \"l1\")\n",
    "        neg = np.array(C1.sum(axis=0))[0] ** l1\n",
    "\n",
    "        neg = neg / neg.sum()\n",
    "\n",
    "        neg = scipy.sparse.diags(neg, format=\"csr\")\n",
    "        neg = mask.dot(neg)\n",
    "        print(\"neg\", time.time() - t1)\n",
    "\n",
    "        C1.data[C1.data <= 0] = 1\n",
    "        neg.data[neg.data <= 0] = 1\n",
    "\n",
    "        C1.data = np.log(C1.data)\n",
    "        neg.data = np.log(neg.data)\n",
    "\n",
    "        C1 -= neg\n",
    "        F = C1\n",
    "        features_matrix = self.get_embedding_rand(F)\n",
    "        return features_matrix\n",
    "\n",
    "    def chebyshev_gaussian(self, A, a, order=10, mu=0.5, s=0.5):\n",
    "        # NE Enhancement via Spectral Propagation\n",
    "        print('Chebyshev Series -----------------')\n",
    "        t1 = time.time()\n",
    "\n",
    "        if order == 1:\n",
    "            return a\n",
    "\n",
    "        A = sp.eye(self.node_number) + A\n",
    "        DA = preprocessing.normalize(A, norm='l1')\n",
    "        L = sp.eye(self.node_number) - DA\n",
    "\n",
    "        M = L - mu * sp.eye(self.node_number)\n",
    "\n",
    "        Lx0 = a\n",
    "        Lx1 = M.dot(a)\n",
    "        Lx1 = 0.5 * M.dot(Lx1) - a\n",
    "\n",
    "        conv = iv(0, s) * Lx0\n",
    "        conv -= 2 * iv(1, s) * Lx1\n",
    "        for i in range(2, order):\n",
    "            Lx2 = M.dot(Lx1)\n",
    "            Lx2 = (M.dot(Lx2) - 2 * Lx1) - Lx0\n",
    "            #         Lx2 = 2*L.dot(Lx1) - Lx0\n",
    "            if i % 2 == 0:\n",
    "                conv += 2 * iv(i, s) * Lx2\n",
    "            else:\n",
    "                conv -= 2 * iv(i, s) * Lx2\n",
    "            Lx0 = Lx1\n",
    "            Lx1 = Lx2\n",
    "            del Lx2\n",
    "            print('Bessell time', i, time.time() - t1)\n",
    "        mm = A.dot(a - conv)\n",
    "        self.embeddings = self.get_embedding_dense(mm, self.emb_size)\n",
    "        return self.embeddings\n",
    "    \n",
    "    def transform(self):\n",
    "        if self.embeddings is None:\n",
    "            print(\"Embedding is not train\")\n",
    "            return {}\n",
    "        self.embeddings = pd.DataFrame(self.embeddings)\n",
    "        self.embeddings.columns = ['ProNE_Emb_{}'.format(i) for i in range(len(self.embeddings.columns))]\n",
    "        self.embeddings = self.embeddings.reset_index().rename(columns={'index' : 'nodes'}).sort_values(by=['nodes'],ascending=True).reset_index(drop=True)\n",
    "\n",
    "        return self.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "#import igraph as ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([train[['uid','qid']],test[['uid','qid']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uid_lbl,qid_lbl = LabelEncoder(),LabelEncoder()\n",
    "data['new_uid'] = uid_lbl.fit_transform(data['uid'])\n",
    "data['new_qid'] = qid_lbl.fit_transform(data['qid'])\n",
    "data['new_qid'] += data['new_uid'].max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_edges_from(data[['new_uid','new_qid']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10628213/10628213 [03:18<00:00, 53564.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2502992, 2502992)\n"
     ]
    }
   ],
   "source": [
    "model = ProNE(G,emb_size=32,n_iter=6,step=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg 10.772807359695435\n",
      "svd sparse 3.3929020498971585e-06\n",
      "sparsesvd time 159.34968185424805\n",
      "Chebyshev Series -----------------\n",
      "Bessell time 2 20.95066475868225\n",
      "Bessell time 3 34.12918448448181\n",
      "Bessell time 4 46.02482032775879\n",
      "Bessell time 5 68.73075819015503\n",
      "Bessell time 6 99.04690909385681\n",
      "Bessell time 7 109.54734110832214\n",
      "Bessell time 8 129.44886469841003\n",
      "Bessell time 9 164.0351173877716\n",
      "Bessell time 10 200.1272099018097\n",
      "Bessell time 11 246.67130994796753\n",
      "densesvd time 52.927714347839355\n"
     ]
    }
   ],
   "source": [
    "features_matrix = model.fit(model.mat, model.mat)\n",
    "model.chebyshev_gaussian(model.mat, features_matrix, model.step, model.mu, model.theta)\n",
    "emb = model.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = emb[emb['nodes'].isin(data['new_uid'])]\n",
    "emb['nodes'] = uid_lbl.inverse_transform(emb['nodes'])\n",
    "emb.rename(columns={'nodes' : 'uid'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb.to_csv('feature_uid_embed.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
